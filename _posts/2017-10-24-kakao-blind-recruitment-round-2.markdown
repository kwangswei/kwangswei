---
title: 카카오 신입 공채 2차 코딩 테스트 문제 해설
layout: post
date: 2017-10-24
category: blog
tag:
- kakao
- recuitment
blog: true
author: kwangswei
---

본 글에는 회사의 의견과는 무관한 개인의 의견이 다수 포함되어 있습니다. 개인의견을 제외한 담백한(이라 쓰고 딱딱한) 글은 카카오 기술 블로그에서 보실 수 있습니다.
------------------


지난 10월 14일(토) 오후 2시부터 10시까지 8시간 동안 온라인 2차 코딩 테스트가 있었습니다. 1차 코딩 테스트와도 사뭇 다른 형식이라 신선했다는 의견도 있고, 당황한 지원자도 있었을 텐데요. 왜 그런 문제를 출제했는지, 출제자의 의도를 한 번 들어볼까요?


# 신입 개발자에게 어떤 역량을 기대하시나요?
1차 코딩 테스트는 어려운 알고리즘 문제가 아닌 자료구조, 알고리즘 등의 전산학 기초에 대해 충분히 학습하였다면 누구나 풀 수 있을만한 "구현" 위주의 문제들로 구성을 하였고, 총 7문제 중 4문제 이상 푼 지원자들에게 2차 기회가 주어졌습니다. 즉, 기본적인 구현 역량은 보유하고 있다고 할 수 있습니다. 

그렇다면 추가적으로 확인해야 할 것은 무엇일까? 이 질문에 대한 답을 찾기 위해 먼저 아래와 같은 질문에 답을 해야만 했습니다.


## 탄탄한 기본기를 바탕으로 새로운 것을 빠르게 습득하는 역량, 작은 단위의 요구사항을 꼼꼼하게 구현해낼 수 있는 역량
경력이 없는 신입사원에게 첫 회사에서 접하는 모든 것들은 새로울 수밖에 없습니다. 그렇기에 빠른 습득 능력은 빼놓을 수 없는 1순위입니다. 또한 첫 입사한 신입은 일반적으로 다른 경험 있는 시니어와 함께 팀을 이루어 함께 문제를 분석/정의하고 일을 좀 더 작은 단위로 쪼개어 일부 요구사항을 구현하는 형태로 진행이 될 것입니다. 이 과정에서 꼼꼼하게 구현한다는 것은, 요구사항을 잘 분석하여 만족하는 구현을 해내는지, 그리고 테스트를 통해 문제없는 프로그램을 작성하는 것이 되겠지요. 그리고 이 과정은 시니어의 리뷰를 받고 다시 반복하는 등 몇 차례의 이터레이션을 돌 것입니다.

이처럼 꼼꼼하게 구현하는 데에 있어서 반드시 필요하면서도, 학교에서는 잘 다루지 않는 영역이 있습니다. 

반복적인 구현이 그렇습니다. 보통 과제 제출 기회는 단 한 번입니다. 그리고 받을 수 있는 피드백이라고는 과제 점수밖에 없지요. 누군가의 리뷰를 받고 수정하는 기회를 갖기란 쉽지 않았을 겁니다. 사실 학습은 이 반복 과정에서 가장 크게 일어나는데 말이지요. 

예외처리, 로깅 및 모니터링도 마찬가지입니다. 회사에 와서 하는 프로젝트는 단기 프로젝트가 아닙니다. 지속적인 서비스 형태가 많지요. 학교 과제처럼 제한된 환경도 아니기 때문에 예외처리를 잘 해야 하고, 내가 구현한 프로그램이 진짜 지속적으로 잘 수행되는지 로그를 남기고, 이를 모니터링하여 문제점을 발견하고 개선하는 과정이 수없이 반복이 됩니다. 

또 한 가지는 트레이드오프(trade-off)입니다. 모든 요구사항을 만족하는 완벽한 솔루션은 아쉽게도 존재하지 않습니다. 매 순간 서로 상충하는 솔루션들 간에 비교를 통해 의사결정을 해야 하는데요.

저는 이런 부분들을 2차 문제에 녹여내고 싶었습니다.

문제에 어떤 장치들이 있었는지 살펴볼까요?



# 이미지 특징값을 수집하는 Crawler 구현
## REST API, JSON Parsing을 이용하라!

2차 테스트 문제는 우선 토큰을 발급받고, 웰컴 서버로부터 5개 카테고리의 Seed URL을 받아온 후 각 카테고리의 문서를 읽어 그 안에 있는 이미지들을 가져와 특징값을 추출하여 서버에 저장/삭제하는 문제입니다. 

쉽게 구현할 수 있는 수준의 요구사항을 주되, 자주 접해보지 않았을 (것으로 추정되는) REST API와 JSON Parsing을 포함시켜 단 시간에 학습하여 풀도록 하였습니다. 사실 사전에 두 가지 키워드를 메일로 전달하였는데요. 이 부분은 내부에서 논란이 많았습니다. 미리 던져주지 않아도 8시간 내에 충분히 검색해서 해결할 수 있는 수준이라는 주장도 있었으나 언어별 편차가 심한 점을 감안하여 사전에 미리 키워드를 제공하였습니다.


## 반복적인 모니터링과 최적화를 유도: 제한된 토큰 유효시간
 토큰의 유효기간은 10분으로 설정하고, 점수 현황판을 제공했습니다. 8시간 동안 스스로 최적화를 하고 한 번만 결과를 제출하도록 하면 일부 지원자는 반복 과정을 통해 최적화를 하지 않을 것 같았습니다. 그래서 다른 사람의 점수를 보고 계속해서 최적화를 수행할 수 있도록 토큰을 10분으로 제한하였습니다. 그리고 수행하는 도중에 문제점이나 병목을 찾으려면 적절히 로그도 남겨야 하고 모니터링도 자연스럽게 하게 될 것이라 생각했지요.

## 전략수립은 평가 메트릭 분석부터!

  | 기호 | 설명                             | 가중치 |
  | ---- | -------------------------------- | ------ |
  | A    | 정상 저장된 이미지 수            | 1.0    |
  | B    | 저장되지 않고 누락된 이미지 수   | -0.8   |
  | C    | 삭제되지 않고 남아있는 이미지 수 | -1.2   |
  | D    | 잘못된 데이터 수                 | -3.0   |
  | E    | 총 쿼리양                        | -0.01  |

 최종점수는 아래 공식으로 산출합니다.
- max(0, 1.0 * A - 0.8 * B - 1.2 * C - 3.0 * D) + 512 - 0.01 * E

평가 메트릭은 최대한 현실적인 부분을 반영하려고 노력했습니다.

누락되거나 삭제되지 않은 이미지에는 페널티를 부여하였는데, 누락보다는 삭제되지 않은 경우에 더 큰 페널티를 주었습니다. 이는 실 상황을 더 반영한 것인데, 누락된 것보다는 삭제되지 않은 이미지가 더 치명적이기 때문입니다. 사용자에게 노출되지 말아야 할 이미지가 삭제되지 않고 노출된 것이, 노출되었으면 좋았을 이미지가 누락되어 노출되지 않은 것보다는 더 치명적일테니까요. 

마찬가지로 잘못된 데이터의 경우 페널티가 가장 큽니다. 데이터가 잘못된 경우 시스템을 서서히 망가뜨리는 데다가, 이를 알아차리기가 쉽지 않기 때문입니다. 

총 쿼리 수에 마이너스 페널티를 준 것은 적절히 요청하지 않아도 되는 것들을 필터링하라는 의도가 반영되었습니다.

## 고득점을 하려면 병렬 처리를!
가장 빈번하게 호출해야 하는 API는 /image/feature입니다. 해당 API의 웰컴 서버에서의 처리 속도는 요청하는 개수에 따라 약 최소 16ms ~ 최대 120ms 까지 걸리도록 디자인하였습니다. 네트워크 지연 시간을 포함하면 싱글 스레드로는 초당 요청 제한인 50건을 채우지 못할 수 있습니다. 따라서 스레드 혹은 프로세스를 최소 2개 이상 생성해야 초당 요청 수 제한을 상회할 수 있습니다.

참고로 웰컴 서버 처리 속도는 배치 처리 개수에 따라 exp 그래프 형태를 취하고 있습니다. 최대 배치 처리 사이즈인 50개씩 보내는 것보다 30~40개 정도가 가장 효율이 좋도록 설계되어 있습니다. 대다수의 지원자가 단건, 혹은 50개씩 요청을 보냈는데, 30개씩 보낸 지원자도 있어 놀랐습니다. (분석을 통해 알아낸 것인지는 잘 모르겠지만 ^_^)

![배치 처리 개수에 따른 응답 시간](http://t1.kakaocdn.net/welcome2018/round2_batch.png)
> 배치 처리 개수에 따른 응답 시간

## 예외처리는 필수
실제 이미지 크롤링을 한다고 생각해봅시다. 크롤링하려고 URL을 큐에 넣어두었는데 그 사이 사용자가 이미지를 삭제했을 수도 있고, 해당 서버가 잠시 내려갔을 수도 있습니다. 웰컴 서버도 이를 시뮬레이션했습니다. 모든 API는 특정 확률 값에 따라 실패하도록 되어 있습니다. 그리고 특정 이미지는 특징값 추출이 매번 실패하도록 고안되었습니다. 재시도 예외처리를 하지 않았다면 해당 요청은 누락되어 감점이 될 것이고, 반복적으로 특징값 추출에 실패하는 이미지를 블록처리하지 않았다면 무의미한 요청이 쌓여 페널티를 받게 됩니다.

## 다양한 시나리오에 대응하라!
문서 내 이미지들의 추가/삭제 간에는 다양한 시나리오가 존재합니다.

- 정상적으로 추가 혹은 삭제되는 경우
- 이미 기존에 추가한 이미지를 또 추가하는 경우
- 방금 추가한 이미지를 바로 삭제하는 경우
- 추가된 적 없는 이미지를 삭제하라고 오는 경우
- 추가, 삭제, 추가가 연달아 오는 경우

모두 현실에 있을 법한 유형들입니다. 보통 인터넷에는 아주 많은 중복 이미지가 존재하고, 이 모든 이미지를 색인하다면 공간 낭비가 크기 때문에, 기존에 이미 추가된 이미지인지 확인하는 단계가 필요합니다. 우리의 온라인 테스트에서는 간단한 메모리 캐시로도 충분합니다. 한 문서 내에 추가/삭제 명령이 연달아 오는 경우도 있습니다. 이 경우에는 웰컴 서버에 추가했다가 삭제할 것이 아니라 서로 상쇄시키면 불필요한 API 요청을 줄일 수 있습니다. 추가된 적 없는 이미지를 삭제하라고 오는 경우도 있습니다. 이 경우도 메모리 캐시를 사용하고 있다면 쉽게 걸러낼 수 있습니다. 마지막 경우는 추가/삭제를 상쇄하는 연산을 할 때 단순히 set을 사용하면 안 되도록 넣어두었습니다. Add A, Del A, Add A 가 올 경우 최종적으로 Add A 만 요청해야 하는데, set으로 합쳐버리면 Add A, Del A 만 남아서 서로 상쇄되어 누락될 것 입니다.

여기서 한 가지 더, 이미지 추가/삭제는 문서 전 영역에 걸쳐 일어납니다. 즉 첫 번째 문서에서 추가한 이미지를 50번째 문서에서 삭제할 수 있습니다. 따라서 50건이 쌓일 때마다 추가/삭제 연산을 요청한 지원자의 경우 이미지 누락을 피할 수 없습니다. 그렇다고 계속 쌓아두다가 막판에 넣으려 하다보면 제한 시간 10분을 초과하여 이미지를 다 넣지 못하는 사태가 생길 수도 있지요. 적절한 선에서 의사결정을 해야 합니다. (트레이드오프) 

## 총 5개의 카테고리
이 곳에도 장치가 마련되어 있습니다. 카테고리별로 이미지의 추가/삭제 비율과 next_url 이 갱신되는 시간에 차등이 있습니다. 시시각각 업데이트되는 news 카테고리 같은 경우 next_url 이 매우 빈번하게 갱신이 됩니다. 반면 art 카테고리는 상대적으로 next_url 이 업데이트 안 될 확률이 7~8배 높습니다. 이미지 데이터량 자체는 blog 카테고리가 가장 풍부합니다. 다만 유저가 올리는 만큼 삭제되는 이미지도 많고, 추가했다가 삭제하는 등의 변동도 가장 크도록 설계되었습니다. 반면 정제된 news는 추가/삭제는 큰 반면 변동은 적습니다.

실제 내부 베타 테스트 진행 시 30만 점을 획득한 한 카카오 개발자는 5개의 카테고리 중 2개는 제외하고 3개 카테고리만 수집하여 30만점 이상의 고득점을 올렸습니다. 이번 온라인 2차 테스트에서도 일부 지원자가 카테고리 1개씩만 시도하는 경우가 발견되었습니다. 단, 여기에도 물론 트레이드오프가 존재합니다. 1개 카테고리만 수집한다고 할 경우 병렬 처리를 하게 되면 문서 간 순서를 보장하는 것이 어려워집니다. 추가적인 구현이 필요하거나 혹은 순서가 뒤틀림에 따라 받게 되는 누락 페널티를 무시하고 양으로 승부할 수도 있겠지요. 다시 한 번, 모든 것이 다 트레이드오프입니다. :)

## 마치며
 여러분은 어느 정도까지 파악하여 진행하셨나요? 

 합격선은 8만 점으로 병렬 처리를 하지 않았더라도 예외처리를 하고, 배치 처리를 했다면 충분히 받을 수 있는 점수이지만, 문제출제위원회는 이렇게 다양하게 장치를 마련해두었고, 또 이런 장치들이 실무에서도 흔하게 발생하는, 그래서 여러분들이 앞으로 고민할 수도 있는 트레이드오프였다는 것을 이야기하고 싶습니다.

 오랜 시간 고생하셨습니다!

# 대회 이모저모

## 언어별 통계

![합격자의 언어 사용 현황](http://t1.kakaocdn.net/welcome2018/round2_language.png)
> 합격자의 언어 사용 현황

2차 합격자들의 언어 분포입니다. 1차 테스트에서는 C++가 25%로 가장 높았으나 파이썬이 42.1%로 압도적으로 높은 비율을 보였고, 자바가 35.1% 로 뒤를 이었습니다. 1차에서는 지원하지 못해 보이지 않았던 C#, Objective-C도 보이고요. 차트에는 보이지 않지만, Go로 푼 지원자도 1명 있어 반가웠습니다. (참고로 이번 2차 테스트에 사용된 웰컴 서버는 모두 Go로 작성되었습니다)

2차 테스트에서 언어 또는 플랫폼을 선택할 때 주의점이 있습니다. 

JavaScript는 64bit 부호가 없는 정수형 타입을 지원하지 않습니다. 따라서 이미지 특징값을 파싱할 때 별도의 라이브러리를 사용하거나 직접 처리를 해줘야 타입 문제로 인한 데이터 오류를 피할 수 있습니다. 

웹브라우저에서 실행할 경우 서버당 병렬로 유지할 수 있는 최대 커넥션 제한이 있어 많은 양을 크롤링하기에 불리합니다.

상대적으로 Python, Go 같은 언어는 유리했을 수 있습니다. 이들 언어는 JSON Parser, REST Client API를 쉽게 지원하고 있고, 타입에 따른 문제도 없으며, Go의 경우는 언어 차원에서 동시성(concurrency)을 풍부하게 지원하고 있어 유리할 수 있겠습니다.

그런데 말입니다, 1등 한 지원자의 코드는 C++ 입니다. :)

프로그래밍 언어 및 플랫폼은 "선택"의 문제이고 문제 해결을 위한 "도구" 입니다. 문제에 따라 적절한 도구를 선택하는 것 못지않게 자신의 도구를 갈고 닦는 것 역시 중요하다 싶습니다.

## 점수 분포

![최종점수 구간별 비율](http://t1.kakaocdn.net/welcome2018/round2_score.png)
> 최종점수 구간별 비율

 최고점은 235,969점이며 응시자 전체 평균은 47,705점입니다. 
 
 대략적인 코드 분석 결과는 아래와 같습니다.

|  병렬처리  |  배치처리  |  예외처리  |  최종점수 |
| ---------- | ----------- | ---------- | --------- |
| X | X | O | 5만점 내외 |
| X | O | O | 14만점 내외 |
| O | O | O | 25만점 내외 |

가장 흥미로웠던 전략은 문서와 이미지 특징값들을 일정 시간 동안 읽고 저장을 마지막에 한꺼번에 처리한 지원자가 있습니다. 이 경우 삭제 API는 아예 요청할 필요가 없으며 누락을 최소화할 수 있겠죠. 이렇게 한 경우 요청 제한의 절반 수준만 사용하고도 15만 점을 웃돌았습니다.

## 트래픽
  2차 온라인 코딩테스트를 준비하면서 가장 심혈을 기울인 부분은 "트래픽 테스트" 입니다. 서버와 통신을 주고받는 형태이다 보니 서버의 응답이 느려지거나 자칫 서버가 죽기라도 한다면......

![아마 난 잘리겠지]({{site.url}}/assets/images/kakaodog.png)
> 아마 난 잘리겠지

![초과 요청 및 요청량 그래프](http://t1.kakaocdn.net/welcome2018/round2_traffic.png)
> 초과 요청 및 요청량 그래프

 우선 일차적으로 토큰별 요청량은 초당 50개로 제한하였습니다. 첫 번째 그래프가 같은 토큰으로 초당 50개 이상씩 던지는 사용자의 요청을 Drop 한 결과입니다. 한 개의 토큰으로 최고 800개/초 요청을 보낸 지원자도 있습니다.

스트레스 테스트는 아래와 같이 수행하였습니다.
1. 우선 예상되는 트래픽의 최대치를 산출합니다. 약 700여 명의 지원자가 초당 50건씩 꽉꽉 채워 보낸다면 초당 약 35,000건을 처리해야 합니다.
1. 웰컴 서버 인스턴스 1개의 처리량을 산출합니다. 그리고 10만 건을 처리할 수 있도록 넣어줍니다. ^___^ (그래 봤자 인스턴스 20개 정도면 충분합니다. 인스턴스 1개당 코어 1개!)
1. 웰컴 서버는 카카오의 데이터센터 운영 플랫폼인 DKOS(Datacenter of Kakao OS) 위에서 동작합니다. DKOS에 Virtual Machine을 생성합니다. 이때 여러 지역의 데이터센터에 적절히 분배하여 한 곳에 몰리는 일이 없도록 합니다. 
1. DKOS는 내부적으로 marathon-lb를 사용합니다. 그래서 marathon-lb 1개의 로드 발란싱 테스트를 수행합니다. 그리고 마찬가지로 10만 건을 처리할 수 있는 수만큼 넣어줍니다 ^___^ (3배는 되어야 발 뻗고 자지!)
1. 가장 상위의 VIP에 모두 연동하고 7~8만건의 더미 데이터를 투척하여 최종 테스트! 
1. 기타 각종 알림 및 모니터링을 위한 대시보드를 구축하면 끝!

네, 그렇습니다. 최고 트래픽은 초당 6000건 정도였네요......(두번째 그래프). 그래도 서버 안 죽고 잘 치렀잖아요? (하아.....쓸데없이 고스펙)


# P.S
회사에서 공식적으로 진행한 행사이다 보니 예민한 부분이 있어서 개인적으로 질문을 하셔도 답변하기 어려울 수 있습니다.

조만간 서울에서 오프라인 모임을 한 번 갖도록 할게요!
